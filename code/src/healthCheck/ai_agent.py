import os
import sys
import subprocess
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer

# Load a pre-trained conversational model (e.g., DialoGPT)
model_name = "microsoft/DialoGPT-medium"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(model_name)

# Function to execute a script and capture its output
def execute_script(script_path):
    try:
        python_executable = sys.executable  # Get the current Python executable
        result = subprocess.run(
            [python_executable, script_path],
            text=True,  # Capture output as text
            capture_output=True,  # Capture stdout and stderr
            check=True,  # Raise an exception if the command fails
        )
        return result.stdout.strip()  # Return the script's standard output
    except subprocess.CalledProcessError as e:
        print(f"Error while executing the script: {e}")
        print(f"Script Output: {e.stdout}")
        print(f"Script Errors: {e.stderr}")
        return f"Error: {e.stderr.strip()}"
    except Exception as e:
        print(f"Unexpected error: {e}")
        return f"Unexpected error: {str(e)}"

# Function to generate a conversational response
def generate_response(prompt):
    inputs = tokenizer.encode(prompt, return_tensors="pt")
    outputs = model.generate(inputs, max_length=100, num_return_sequences=1, pad_token_id=tokenizer.eos_token_id)
    response = tokenizer.decode(outputs[0], skip_special_tokens=True)
    return response

# Main logic
if __name__ == "__main__":
    # Path to the script to execute
    script_path = "test.py"  # Replace with the path to your script

    # Execute the script and get its output
    script_output = execute_script(script_path)

    # Generate a conversational response based on the script's output
    if script_output:
        prompt = f"You are an assistant that explains Prometheus metric data. The script output is:\n{script_output}\nExplain this to me."
        response = generate_response(prompt)
        print("Agent Response:")
        print(response)
    else:
        print("No output was generated by the script.")
